{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the LSTM model\n",
    "## Goal\n",
    "Understand how the LSTM model works and try to play with it\n",
    "## Coding\n",
    "### 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import math, json, datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a LSTM class to manage operations with the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM:\n",
    "    PRIOR_DAY_AMOUNT = 50\n",
    "    \n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol\n",
    "        self.model = self.build_model()\n",
    "        self.__init_all_data()\n",
    "        self.load_model()\n",
    "        \n",
    "    def __init_all_data(self):\n",
    "        self.all_data = []\n",
    "        with open(\"dataset/%s.json\" % self.symbol, 'r') as openfile:\n",
    "            self.all_data = json.load(openfile)    \n",
    "        \n",
    "    def __init_training_data(self):\n",
    "        # to remove the datetime from the data\n",
    "        scale, _ = zip(*self.all_data)\n",
    "        \n",
    "        self.scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scale = np.array(scale)\n",
    "        stock_price_history = self.scaler.fit_transform(scale.reshape(-1,1)).reshape(-1)\n",
    "        self.training_data_x = []\n",
    "        self.training_data_y = []\n",
    "        \n",
    "        training_data_len = math.ceil(len(stock_price_history)* 0.8)\n",
    "        for i in range(self.PRIOR_DAY_AMOUNT, training_data_len):\n",
    "            self.training_data_x.append(stock_price_history[i-self.PRIOR_DAY_AMOUNT:i])\n",
    "            self.training_data_y.append(stock_price_history[i])\n",
    "        \n",
    "        self.training_data_x, self.training_data_y = np.array(self.training_data_x), np.array(self.training_data_y)\n",
    "        self.training_data_x = np.reshape(self.training_data_x, (self.training_data_x.shape[0], self.training_data_x.shape[1], 1))\n",
    "        self.test = self.training_data_x[-1]\n",
    "        \n",
    "    def __delete_training_data(self):\n",
    "        self.training_data_x, self.training_data_y = None, None\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        model.add(keras.layers.LSTM(100, return_sequences=True, input_shape=(self.PRIOR_DAY_AMOUNT, 1)))\n",
    "        model.add(keras.layers.LSTM(100, return_sequences=False))\n",
    "        model.add(keras.layers.Dense(25))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, batch_size=None, epochs=50):\n",
    "        self.__init_training_data()\n",
    "        \n",
    "        if batch_size is None:\n",
    "            batch_size = (len(self.all_data) // 350) + 1\n",
    "            \n",
    "        self.model.fit(self.training_data_x, self.training_data_y, batch_size=batch_size, epochs=epochs)\n",
    "        self.save_model()\n",
    "        #self.__delete_training_data()\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.model.save_weights(\"parameters/%s/\" % self.symbol)\n",
    "    \n",
    "    def load_model(self):\n",
    "        try:\n",
    "            self.model.load_weights(\"parameters/%s/\" % self.symbol)\n",
    "        except:\n",
    "            print(\"Couldn't load the parameters : the parameters file doesn't exist\")\n",
    "            \n",
    "    \"\"\"\n",
    "        Give predicted price on the given date\n",
    "    \"\"\"\n",
    "    def predict(self, date):\n",
    "        # Check if date is from monday to friday\n",
    "        date_to_predict = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        if date_to_predict.weekday() >= 5:\n",
    "            return None\n",
    "        \n",
    "        last_date = self.all_data[-1][1]\n",
    "        # Generate needed inputs to predict the price at given date\n",
    "        \n",
    "        date_to_predict = np.datetime64(date)\n",
    "        last_date = np.datetime64(last_date)\n",
    "        \n",
    "        business_days_count = np.busday_count(last_date, date_to_predict)\n",
    "        \n",
    "        prices, _ = zip(*self.all_data)\n",
    "        prices = list(self.scaler.fit_transform(np.array(prices).reshape(-1,1)).reshape(-1))\n",
    "        if business_days_count > 0:\n",
    "            # Feedforward to get answers and filling inputs as needed\n",
    "            while business_days_count >= 0:\n",
    "                inp = np.array(prices[-self.PRIOR_DAY_AMOUNT:]).reshape((1,self.PRIOR_DAY_AMOUNT,1))\n",
    "                prices.append(self.model.predict(inp)[0][0])\n",
    "                print(prices[-1])\n",
    "                business_days_count -= 1\n",
    "                \n",
    "            return prices[-1]\n",
    "        else:\n",
    "            # We got the required data to predict\n",
    "            inp = np.array(prices[(-self.PRIOR_DAY_AMOUNT + business_days_count - 1):(business_days_count - 1)]).reshape((1,self.PRIOR_DAY_AMOUNT,1))\n",
    "            return self.model.predict(inp)[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 50, 100)           40800     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 25)                2525      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,751\n",
      "Trainable params: 123,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "264/264 [==============================] - 5s 11ms/step - loss: 4.3724e-06\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 4.6665e-06\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 4.7969e-06\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 4.5041e-06\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 5.5436e-06\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 3s 12ms/step - loss: 5.5455e-06\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 3s 12ms/step - loss: 5.0941e-06\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 5.7564e-06\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 5.6576e-06\n",
      "Epoch 10/10\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 5.3511e-06\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 50, 100)           40800     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 25)                2525      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,751\n",
      "Trainable params: 123,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1318/1318 [==============================] - 15s 10ms/step - loss: 1.3987e-05\n",
      "Epoch 2/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 9.9848e-06\n",
      "Epoch 3/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 8.1614e-06\n",
      "Epoch 4/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 1.0228e-05\n",
      "Epoch 5/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 8.8820e-06\n",
      "Epoch 6/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 8.9252e-06\n",
      "Epoch 7/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 9.8010e-06\n",
      "Epoch 8/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 9.3341e-06\n",
      "Epoch 9/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 7.7451e-06\n",
      "Epoch 10/10\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 7.9953e-06\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(\"AAPL\")\n",
    "model.train(epochs=10)\n",
    "\n",
    "model1 = LSTM(\"AAPL\")\n",
    "model1.train(batch_size=3,epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try to predict future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 449ms/step\n",
      "[[142.50472694]]\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "[[135.62764354]]\n"
     ]
    }
   ],
   "source": [
    "# I will try to predict Apple share price for 2023/02/22\n",
    "date = \"2023-02-07\"\n",
    "price = model.predict(date)\n",
    "print(model.scaler.inverse_transform([[price]]))\n",
    "\n",
    "print(model1.scaler.inverse_transform([[model1.predict(date)]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Try different config for the training.\n",
    "For example, we can check \n",
    "1. which optimizer predicts the future best\n",
    "2. which loss function minimize the overall loss of the model\n",
    "3. modify the amount of layers / amount of node per layer \n",
    "4. mix of #1, #2 and #3 with different batch_size and epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "010d72da20a09e5bca4b1cca71edb635b8a8a147b32fbccaea84cbf59b145b1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
